{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cc3db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afc8a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('fashion-mnist_train.csv')\n",
    "test=pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7c09bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8   \n",
       "0      2       0       0       0       0       0       0       0       0  \\\n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780   \n",
       "0       0  ...         0         0         0         0         0         0  \\\n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77b7bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=train.drop('label',axis=1)\n",
    "trainy=train['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f119bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "testx=test.drop('label',axis=1)\n",
    "testy=test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26991e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=trainx.to_numpy()\n",
    "trainy=trainy.to_numpy()\n",
    "\n",
    "testx=testx.to_numpy()\n",
    "testy=testy.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "981ac4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30fd5bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acdc11bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1202b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=trainx.reshape((60000,28,28))\n",
    "testx=testx.reshape((10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36562e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5537c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c4e6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann=models.Sequential([\n",
    "    layers.Flatten(input_shape=(28,28)),\n",
    "    layers.Dense(3000,activation='relu'),\n",
    "    layers.Dense(1000,activation='relu'),\n",
    "    layers.Dense(10,activation='sigmoid')\n",
    "])\n",
    "\n",
    "ann.compile(optimizer='adam',\n",
    "           loss='sparse_categorical_crossentropy',\n",
    "           metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b353a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 134s 71ms/step - loss: 3.1773 - accuracy: 0.7930\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 132s 70ms/step - loss: 0.4497 - accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x198c67bfdd0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(trainx,trainy,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "651419d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4348 - accuracy: 0.8443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4347638189792633, 0.8442999720573425]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(testx,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c6982e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=models.Sequential([\n",
    "     layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    layers.Flatten(input_shape=(28,28)),\n",
    "    layers.Dense(1000,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "           loss='sparse_categorical_crossentropy',\n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8237b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MaxPooling2D in module keras.layers.pooling.max_pooling2d:\n",
      "\n",
      "class MaxPooling2D(keras.layers.pooling.base_pooling2d.Pooling2D)\n",
      " |  MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)\n",
      " |  \n",
      " |  Max pooling operation for 2D spatial data.\n",
      " |  \n",
      " |  Downsamples the input along its spatial dimensions (height and width)\n",
      " |  by taking the maximum value over an input window\n",
      " |  (of size defined by `pool_size`) for each channel of the input.\n",
      " |  The window is shifted by `strides` along each dimension.\n",
      " |  \n",
      " |  The resulting output,\n",
      " |  when using the `\"valid\"` padding option, has a spatial shape\n",
      " |  (number of rows or columns) of:\n",
      " |  `output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n",
      " |  (when `input_shape >= pool_size`)\n",
      " |  \n",
      " |  The resulting output shape when using the `\"same\"` padding option is:\n",
      " |  `output_shape = math.floor((input_shape - 1) / strides) + 1`\n",
      " |  \n",
      " |  For example, for `strides=(1, 1)` and `padding=\"valid\"`:\n",
      " |  \n",
      " |  >>> x = tf.constant([[1., 2., 3.],\n",
      " |  ...                  [4., 5., 6.],\n",
      " |  ...                  [7., 8., 9.]])\n",
      " |  >>> x = tf.reshape(x, [1, 3, 3, 1])\n",
      " |  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
      " |  ...    strides=(1, 1), padding='valid')\n",
      " |  >>> max_pool_2d(x)\n",
      " |  <tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
      " |    array([[[[5.],\n",
      " |             [6.]],\n",
      " |            [[8.],\n",
      " |             [9.]]]], dtype=float32)>\n",
      " |  \n",
      " |  For example, for `strides=(2, 2)` and `padding=\"valid\"`:\n",
      " |  \n",
      " |  >>> x = tf.constant([[1., 2., 3., 4.],\n",
      " |  ...                  [5., 6., 7., 8.],\n",
      " |  ...                  [9., 10., 11., 12.]])\n",
      " |  >>> x = tf.reshape(x, [1, 3, 4, 1])\n",
      " |  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
      " |  ...    strides=(2, 2), padding='valid')\n",
      " |  >>> max_pool_2d(x)\n",
      " |  <tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=\n",
      " |    array([[[[6.],\n",
      " |             [8.]]]], dtype=float32)>\n",
      " |  \n",
      " |  Usage Example:\n",
      " |  \n",
      " |  >>> input_image = tf.constant([[[[1.], [1.], [2.], [4.]],\n",
      " |  ...                            [[2.], [2.], [3.], [2.]],\n",
      " |  ...                            [[4.], [1.], [1.], [1.]],\n",
      " |  ...                            [[2.], [2.], [1.], [4.]]]])\n",
      " |  >>> output = tf.constant([[[[1], [0]],\n",
      " |  ...                       [[0], [1]]]])\n",
      " |  >>> model = tf.keras.models.Sequential()\n",
      " |  >>> model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
      " |  ...    input_shape=(4, 4, 1)))\n",
      " |  >>> model.compile('adam', 'mean_squared_error')\n",
      " |  >>> model.predict(input_image, steps=1)\n",
      " |  array([[[[2.],\n",
      " |           [4.]],\n",
      " |          [[4.],\n",
      " |           [4.]]]], dtype=float32)\n",
      " |  \n",
      " |  For example, for stride=(1, 1) and padding=\"same\":\n",
      " |  \n",
      " |  >>> x = tf.constant([[1., 2., 3.],\n",
      " |  ...                  [4., 5., 6.],\n",
      " |  ...                  [7., 8., 9.]])\n",
      " |  >>> x = tf.reshape(x, [1, 3, 3, 1])\n",
      " |  >>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
      " |  ...    strides=(1, 1), padding='same')\n",
      " |  >>> max_pool_2d(x)\n",
      " |  <tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
      " |    array([[[[5.],\n",
      " |             [6.],\n",
      " |             [6.]],\n",
      " |            [[8.],\n",
      " |             [9.],\n",
      " |             [9.]],\n",
      " |            [[8.],\n",
      " |             [9.],\n",
      " |             [9.]]]], dtype=float32)>\n",
      " |  \n",
      " |  Args:\n",
      " |    pool_size: integer or tuple of 2 integers,\n",
      " |      window size over which to take the maximum.\n",
      " |      `(2, 2)` will take the max value over a 2x2 pooling window.\n",
      " |      If only one integer is specified, the same window length\n",
      " |      will be used for both dimensions.\n",
      " |    strides: Integer, tuple of 2 integers, or None.\n",
      " |      Strides values.  Specifies how far the pooling window moves\n",
      " |      for each pooling step. If None, it will default to `pool_size`.\n",
      " |    padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |      `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n",
      " |      the left/right or up/down of the input such that output has the same\n",
      " |      height/width dimension as the input.\n",
      " |    data_format: A string,\n",
      " |      one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs.\n",
      " |      `channels_last` corresponds to inputs with shape\n",
      " |      `(batch, height, width, channels)` while `channels_first`\n",
      " |      corresponds to inputs with shape\n",
      " |      `(batch, channels, height, width)`.\n",
      " |      It defaults to the `image_data_format` value found in your\n",
      " |      Keras config file at `~/.keras/keras.json`.\n",
      " |      If you never set it, then it will be \"channels_last\".\n",
      " |  \n",
      " |  Input shape:\n",
      " |    - If `data_format='channels_last'`:\n",
      " |      4D tensor with shape `(batch_size, rows, cols, channels)`.\n",
      " |    - If `data_format='channels_first'`:\n",
      " |      4D tensor with shape `(batch_size, channels, rows, cols)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    - If `data_format='channels_last'`:\n",
      " |      4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n",
      " |    - If `data_format='channels_first'`:\n",
      " |      4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.\n",
      " |  \n",
      " |  Returns:\n",
      " |    A tensor of rank 4 representing the maximum pooled values.  See above for\n",
      " |    output shape.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MaxPooling2D\n",
      " |      keras.layers.pooling.base_pooling2d.Pooling2D\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
      " |      tensorflow.python.trackable.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.layers.pooling.base_pooling2d.Pooling2D:\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      The `call()` method may not create state (except in its first\n",
      " |      invocation, wrapping the creation of variables or other resources in\n",
      " |      `tf.init_scope()`).  It is recommended to create state, including\n",
      " |      `tf.Variable` instances and nested `Layer` instances,\n",
      " |       in `__init__()`, or in the `build()` method that is\n",
      " |      called automatically before `call()` executes for the first time.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as\n",
      " |            tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs`\n",
      " |            only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask\n",
      " |            generated for `inputs` by the previous layer (if `input` did come\n",
      " |            from a layer that generated a corresponding mask, i.e. if it came\n",
      " |            from a Keras layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      This method will cause the layer's state to be built, if that has not\n",
      " |      happened before. This requires that the layer will later be used with\n",
      " |      inputs that match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers) or `tf.TensorShape`,\n",
      " |              or structure of shape tuples / `tf.TensorShape` instances\n",
      " |              (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `tf.TensorShape` instance\n",
      " |          or structure of `tf.TensorShape` instances.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of\n",
      " |      dict every time it is called. The callers should make a copy of the\n",
      " |      returned dict if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific\n",
      " |          uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid\n",
      " |          value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the\n",
      " |          constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be\n",
      " |      dependent on the inputs passed when calling a layer. Hence, when reusing\n",
      " |      the same layer on different inputs `a` and `b`, some entries in\n",
      " |      `layer.losses` may be dependent on `a` and some on `b`. This method\n",
      " |      automatically keeps track of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      The same code works in distributed training: the input to `add_loss()`\n",
      " |      is treated like a regularization loss and averaged across replicas\n",
      " |      by the training loop (both built-in `Model.fit()` and compliant custom\n",
      " |      training loops).\n",
      " |      \n",
      " |      The `add_loss` method can also be called directly on a Functional Model\n",
      " |      during construction. In this case, any loss Tensors passed to this Model\n",
      " |      must be symbolic and be able to be traced back to the model's `Input`s.\n",
      " |      These losses become part of the model's topology and are tracked in\n",
      " |      `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss\n",
      " |      references a `Variable` of one of the model's layers), you can wrap your\n",
      " |      loss in a zero-argument lambda. These losses are not tracked as part of\n",
      " |      the model's topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n",
      " |          losses may also be zero-argument callables which create a loss\n",
      " |          tensor.\n",
      " |        **kwargs: Used for backwards compatibility only.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This\n",
      " |      is because we cannot trace the metric result tensor back to the model's\n",
      " |      inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result\n",
      " |          of calling a `keras.Metric` instance, it will be aggregated by\n",
      " |          default using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and\n",
      " |      variance in a BatchNormalization layer) may be dependent on the inputs\n",
      " |      passed when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case,\n",
      " |      variable updates are run on the fly and thus do not need to be tracked\n",
      " |      for later execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use a `ResourceVariable` or not.\n",
      " |          See [this guide](\n",
      " |          https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |           for more information.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set\n",
      " |          to `AUTO` and the current `DistributionStrategy` chooses when to\n",
      " |          synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n",
      " |          must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as\n",
      " |          `ON_READ`.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call. It is invoked automatically before\n",
      " |      the first execution of `call()`.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses\n",
      " |      (at the discretion of the subclass implementer).\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  build_from_config(self, config)\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects,\n",
      " |          describing how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after\n",
      " |      updating a layer weights. It can be overridden to finalize any\n",
      " |      additional layer state after a weight update.\n",
      " |      \n",
      " |      This function will be called after weights of a layer have been restored\n",
      " |      from a loaded model.\n",
      " |  \n",
      " |  get_build_config(self)\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with\n",
      " |      this layer as a list of NumPy arrays, which can in turn be used to load\n",
      " |      state into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel\n",
      " |      matrix and the bias vector. These can be used to set the weights of\n",
      " |      another `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which\n",
      " |      causes computations and the output to be in the compute dtype as well.\n",
      " |      This is done by the base Layer class in `Layer.__call__`, so you do not\n",
      " |      have to insert these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision\n",
      " |      when `compute_dtype` is float16 or bfloat16 for numeric stability. The\n",
      " |      output will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Return Functional API nodes upstream of this layer.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is\n",
      " |      accessed, so it is eager safe: accessing `losses` under a\n",
      " |      `tf.GradientTape` will propagate gradients back to the corresponding\n",
      " |      variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are\n",
      " |      expected to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Return Functional API nodes downstream of this layer.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are\n",
      " |      not themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to\n",
      " |      enable the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input\n",
      " |      tensor of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a\n",
      " |      nicely-formatted error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(layers.MaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d91bec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 56s 29ms/step - loss: 0.6832 - accuracy: 0.7955\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.3780 - accuracy: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x198f9f68e90>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(trainx,trainy,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7f0dedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3299 - accuracy: 0.8781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32986700534820557, 0.8780999779701233]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(testx,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74dcb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot(x,y,i):\n",
    "    plt.figure(figsize=(15,2))\n",
    "    plt.imshow(x[i])\n",
    "    plt.xlabel(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "21b1153b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(trainx,trainy,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "580e35a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred=cnn.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "750b9bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.75855577e-01, 4.64260265e-05, 1.53297270e-02, 5.47452411e-03,\n",
       "        1.37701328e-03, 3.58491197e-05, 3.00648421e-01, 1.11107465e-06,\n",
       "        1.22697325e-03, 4.34122649e-06],\n",
       "       [4.86380762e-11, 1.00000000e+00, 5.26627700e-11, 8.60250182e-09,\n",
       "        2.36755873e-13, 1.41387203e-16, 1.86333615e-10, 3.11800868e-17,\n",
       "        4.47591226e-12, 1.27010605e-17],\n",
       "       [5.11378497e-02, 2.28113572e-06, 9.03957307e-01, 5.17650507e-03,\n",
       "        2.66461226e-04, 1.88242357e-05, 3.94154713e-02, 5.77993440e-08,\n",
       "        2.42607493e-05, 1.00424404e-06],\n",
       "       [2.79291067e-03, 1.55141272e-04, 9.41043198e-01, 1.79380237e-03,\n",
       "        3.54846846e-03, 2.62495669e-05, 5.06125726e-02, 1.31774144e-07,\n",
       "        2.75725561e-05, 3.81775429e-08],\n",
       "       [2.92227254e-03, 2.19514011e-03, 1.41828014e-02, 9.19780791e-01,\n",
       "        5.63682569e-03, 7.60862255e-04, 2.70156059e-02, 2.77996296e-05,\n",
       "        2.74327770e-02, 4.50392909e-05]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc851b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "yclass=[np.argmax(e) for e in ypred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b45beada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 2, 3]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yclass[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83a3cad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aba84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
